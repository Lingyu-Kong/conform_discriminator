Traceback (most recent call last):
  File "dmcg_main.py", line 118, in <module>
    intrinsic_loss,extrinsic_loss,intrinsic_rewards,extrinsic_rewards = discriminator.compute_loss_and_train(conforms, energy)
  File "/home/v-linyukong/work/conform_discriminator/DMCG_Discriminator/dmcg_discriminator.py", line 53, in compute_loss_and_train
    intrinsic_predict, extrinsic_predict = self.predict(conforms)
  File "/home/v-linyukong/work/conform_discriminator/DMCG_Discriminator/dmcg_discriminator.py", line 40, in predict
    extrinsic_predict=self.extrinsic_model(conforms)
  File "/home/v-linyukong/miniconda3/envs/crystal_generation/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/v-linyukong/work/conform_discriminator/DMCG_model/dmcg_nn.py", line 133, in forward
    node_attr_1,edge_attr_1,global_attr_1=layer(
  File "/home/v-linyukong/miniconda3/envs/crystal_generation/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/v-linyukong/work/conform_discriminator/DMCG_model/meta_layer.py", line 80, in forward
    edge_attributes=self.global_edge_attn(torch.repeat_interleave(global_attr, num_edges, dim=0),edge_attr,edge_batch,global_attr.size(0))
  File "/home/v-linyukong/miniconda3/envs/crystal_generation/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/v-linyukong/work/conform_discriminator/DMCG_model/meta_layer.py", line 246, in forward
    x = F.leaky_relu(x)
  File "/home/v-linyukong/miniconda3/envs/crystal_generation/lib/python3.8/site-packages/torch/nn/functional.py", line 1618, in leaky_relu
    result = torch._C._nn.leaky_relu(input, negative_slope)
RuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.61 GiB total capacity; 13.50 GiB already allocated; 20.56 MiB free; 13.53 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF