Traceback (most recent call last):
  File "main.py", line 128, in <module>
    intrinsic_loss,extrinsic_loss,intrinsic_reward,extrinsic_reward = discriminator.compute_loss_and_train(conforms, relax_energy)
  File "/home/v-linyukong/work/conform_discriminator/discriminator.py", line 65, in compute_loss_and_train
    intrinsic_predict, extrinsic_predict = self.predict(conforms)
  File "/home/v-linyukong/work/conform_discriminator/discriminator.py", line 48, in predict
    intrinsic_predict = self.intrinsic_model(
  File "/home/v-linyukong/miniconda3/envs/crystal_generation/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/v-linyukong/work/conform_discriminator/model/ignn.py", line 73, in forward
    h=self.module_list[i](x,h,edge_index,edge_attr)
  File "/home/v-linyukong/miniconda3/envs/crystal_generation/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/v-linyukong/work/conform_discriminator/model/ignn_layer.py", line 97, in forward
    message=self.phi_e_model_forward(h[row],h[col],radial,edge_attr)
  File "/home/v-linyukong/work/conform_discriminator/model/ignn_layer.py", line 64, in phi_e_model_forward
    message=phi_e_output*att_val
RuntimeError: CUDA out of memory. Tried to allocate 632.00 MiB (GPU 0; 14.76 GiB total capacity; 12.48 GiB already allocated; 528.94 MiB free; 13.10 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF